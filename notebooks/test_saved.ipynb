{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "# import os\n",
    "# import sklearn\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "import joblib\n",
    "\n",
    "# import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../finalised_model_scale_encode/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = keras.models.model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_chunk, sampling_rate):\n",
    "    y  = audio_chunk\n",
    "    sr = sampling_rate\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_cont = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spec_flat = librosa.feature.spectral_flatness(y=y)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    poly = librosa.feature.poly_features(y=y,sr=sr)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y,sr=sr)\n",
    "    to_append = f'{np.mean(chroma_stft)} {np.mean(chroma_cqt)} {np.mean(chroma_cens)} {np.mean(rms)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(spec_cont)} {np.mean(spec_flat)} {np.mean(rolloff)} {np.mean(zcr)} {np.mean(poly)} {np.mean(tonnetz)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    return np.array(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(features):\n",
    "    # TODO: Get scaler instead of directly using this:\n",
    "#     print(features)\n",
    "    return scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = joblib.load('../finalised_model_scale_encode/label.encoder')\n",
    "scaler = joblib.load('../finalised_model_scale_encode/feature.scalar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayank.gupta/venv/audio/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "test_audio = '../validation_data/test_audio.mp4'\n",
    "y1 , sr = librosa.load(test_audio, sr=44100)\n",
    "# ipd.Audio(test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = '../validation_data/test_audio2.wav'\n",
    "y2 , sr = librosa.load(test_audio, sr=44100)\n",
    "# ipd.Audio(test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayank.gupta/venv/audio/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "test_audio = '../validation_data/test_audio3.mp3'\n",
    "y3 , sr = librosa.load(test_audio, sr=44100)\n",
    "# ipd.Audio(test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.48648223733938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y3)/44100/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 to 1.0: [0]\n",
      "1.0 to 2.0: [1]\n",
      "2.0 to 3.0: [1]\n",
      "3.0 to 4.0: [0]\n",
      "4.0 to 5.0: [1]\n",
      "5.0 to 6.0: [0]\n",
      "6.0 to 7.0: [1]\n",
      "7.0 to 8.0: [1]\n",
      "8.0 to 9.0: [0]\n",
      "9.0 to 10.0: [1]\n",
      "10.0 to 11.0: [1]\n",
      "11.0 to 12.0: [0]\n",
      "12.0 to 13.0: [1]\n",
      "13.0 to 14.0: [0]\n",
      "14.0 to 15.0: [1]\n",
      "15.0 to 16.0: [1]\n",
      "16.0 to 17.0: [0]\n",
      "17.0 to 18.0: [1]\n",
      "18.0 to 19.0: [0]\n",
      "19.0 to 20.0: [0]\n",
      "20.0 to 21.0: [0]\n",
      "21.0 to 22.0: [0]\n",
      "22.0 to 23.0: [0]\n",
      "23.0 to 24.0: [0]\n",
      "24.0 to 25.0: [0]\n",
      "25.0 to 26.0: [0]\n",
      "26.0 to 27.0: [0]\n",
      "27.0 to 28.0: [0]\n",
      "28.0 to 29.0: [0]\n",
      "29.0 to 30.0: [0]\n",
      "30.0 to 31.0: [0]\n",
      "31.0 to 32.0: [0]\n",
      "32.0 to 33.0: [0]\n",
      "33.0 to 34.0: [0]\n",
      "34.0 to 35.0: [0]\n",
      "35.0 to 36.0: [0]\n",
      "36.0 to 37.0: [0]\n",
      "37.0 to 38.0: [0]\n",
      "38.0 to 39.0: [0]\n"
     ]
    }
   ],
   "source": [
    "minus_i = 0\n",
    "for i in range(44100,len(y1[:40*sr,]), 44100):\n",
    "    chunk = y1[minus_i:i,]\n",
    "#     print(chunk)\n",
    "    print(f'{minus_i/44100} to {i/44100}:', model.predict_classes(scale_features([extract_features(chunk, 44100)])))\n",
    "    minus_i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Audio",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
